{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUILDING SVM MODELS TO DETECT BIG FIVE PERSONALITY TRAITS IN A DUTCH CORPUS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, we start with importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, re, string\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "\n",
    "# the below line is the major difference to file \"csi_svm_kp\"\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "from nltk import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.feature_extraction.text import TfidfTransformer \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, f1_score, hamming_loss, precision_score, recall_score\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/stegerakos/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/stegerakos/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "stemmer = SnowballStemmer(\"dutch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will assign names to the columns, since the data came without these\n",
    "col = [\"Participant\", \"Born\", \"Gender\", \"LGBT\", \"Residence\", \"Country\", \"BigFive\", \"MBTI\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = pd.read_csv(\"csicorpus/List.CSI.AuthorData.1.4.0.BV.2016-02-08.txt\", sep = \"\\t\", names = col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant</th>\n",
       "      <th>Born</th>\n",
       "      <th>Gender</th>\n",
       "      <th>LGBT</th>\n",
       "      <th>Residence</th>\n",
       "      <th>Country</th>\n",
       "      <th>BigFive</th>\n",
       "      <th>MBTI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60235486</td>\n",
       "      <td>1990</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Antwerpen</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>----</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43931362</td>\n",
       "      <td>1991</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Antwerpen</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>----</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11987873</td>\n",
       "      <td>1988-17-04</td>\n",
       "      <td>Male</td>\n",
       "      <td>Straight</td>\n",
       "      <td>Antwerpen</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>93-30-53-32-22</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>98696422</td>\n",
       "      <td>1986-26-07</td>\n",
       "      <td>Male</td>\n",
       "      <td>Straight</td>\n",
       "      <td>Antwerpen</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>90-47-48-22-37</td>\n",
       "      <td>I44-N50-T01-J11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36964375</td>\n",
       "      <td>1990</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Antwerpen</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>----</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Participant        Born  Gender      LGBT  Residence  Country  \\\n",
       "0     60235486        1990  Female       NaN  Antwerpen  Belgium   \n",
       "1     43931362        1991  Female       NaN  Antwerpen  Belgium   \n",
       "2     11987873  1988-17-04    Male  Straight  Antwerpen  Belgium   \n",
       "3     98696422  1986-26-07    Male  Straight  Antwerpen  Belgium   \n",
       "4     36964375        1990  Female       NaN  Antwerpen  Belgium   \n",
       "\n",
       "          BigFive             MBTI  \n",
       "0            ----              ---  \n",
       "1            ----              ---  \n",
       "2  93-30-53-32-22              ---  \n",
       "3  90-47-48-22-37  I44-N50-T01-J11  \n",
       "4            ----              ---  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjects.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We eliminate duplicates\n",
    "subjects.drop_duplicates(subset='Participant', keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "668"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'59260694'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We devise a function that extracts user ID from a file name\n",
    "def user_id(filename):\n",
    "    return filename.split(\"_\")[0]\n",
    "\n",
    "user_id(\"59260694_Essay_2014-06-01.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing the path\n",
    "path = \"./csicorpus/essays/\" \n",
    "# Setting up a new empty data list here, into which we will place our txt files\n",
    "data_list = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A for-loop reads the data of the txt files\n",
    "\n",
    "for filename in os.listdir(path):\n",
    "    if filename != \".ipynb_checkpoints\":\n",
    "        data = open(path+filename, \"r\").read()\n",
    "        data_list.append(\n",
    "            {\n",
    "            'Participant': user_id(filename),\n",
    "            'filename': filename,\n",
    "            'Essay': data\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant</th>\n",
       "      <th>filename</th>\n",
       "      <th>Essay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92419385</td>\n",
       "      <td>92419385_Essay_2015-01-06.txt</td>\n",
       "      <td>Het orgaandonorschap: een dualistische visie\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89353110</td>\n",
       "      <td>89353110_Essay_2015-01-06.txt</td>\n",
       "      <td>Iedereen automatisch geregistreerd als donor, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30423159</td>\n",
       "      <td>30423159_Essay_2012.txt</td>\n",
       "      <td>Gezond leven: het middel om langer te leven?\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>95257163</td>\n",
       "      <td>95257163_Paper_2014-06-01.txt</td>\n",
       "      <td>﻿Inleiding\\nWe kunnen er niet omheen dat het E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34322552</td>\n",
       "      <td>34322552_Essay_2013-06-01.txt</td>\n",
       "      <td>Enkele jaren geleden was men er zeker van dat ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Participant                       filename  \\\n",
       "0    92419385  92419385_Essay_2015-01-06.txt   \n",
       "1    89353110  89353110_Essay_2015-01-06.txt   \n",
       "2    30423159        30423159_Essay_2012.txt   \n",
       "3    95257163  95257163_Paper_2014-06-01.txt   \n",
       "4    34322552  34322552_Essay_2013-06-01.txt   \n",
       "\n",
       "                                               Essay  \n",
       "0  Het orgaandonorschap: een dualistische visie\\n...  \n",
       "1  Iedereen automatisch geregistreerd als donor, ...  \n",
       "2  Gezond leven: het middel om langer te leven?\\n...  \n",
       "3  ﻿Inleiding\\nWe kunnen er niet omheen dat het E...  \n",
       "4  Enkele jaren geleden was men er zeker van dat ...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essays = pd.DataFrame(data_list)\n",
    "\n",
    "essays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 517 entries, 0 to 516\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Participant  517 non-null    object\n",
      " 1   filename     517 non-null    object\n",
      " 2   Essay        517 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 12.2+ KB\n"
     ]
    }
   ],
   "source": [
    "essays.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we can see that we succesfully extracted the essay data from the files into a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning our data\n",
    "\n",
    "First, we will have to merge our two dataframes: `subjects` and `essays` before going on to the preprocessing task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure 'Participants' are strings\n",
    "subjects.Participant = subjects.Participant.astype(str) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(essays[[\"Participant\", \"Essay\"]], subjects[[\"Participant\", \"BigFive\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant</th>\n",
       "      <th>Essay</th>\n",
       "      <th>BigFive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92419385</td>\n",
       "      <td>Het orgaandonorschap: een dualistische visie\\n...</td>\n",
       "      <td>84-58-95-6-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89353110</td>\n",
       "      <td>Iedereen automatisch geregistreerd als donor, ...</td>\n",
       "      <td>1-41-70-8-80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30423159</td>\n",
       "      <td>Gezond leven: het middel om langer te leven?\\n...</td>\n",
       "      <td>1-86-4-50-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30423159</td>\n",
       "      <td>Werken tot 65 jaar zorgt voor meer psychische ...</td>\n",
       "      <td>1-86-4-50-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30423159</td>\n",
       "      <td>In 2012 is er een wet doorgekomen die het drag...</td>\n",
       "      <td>1-86-4-50-27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Participant                                              Essay  \\\n",
       "0    92419385  Het orgaandonorschap: een dualistische visie\\n...   \n",
       "1    89353110  Iedereen automatisch geregistreerd als donor, ...   \n",
       "2    30423159  Gezond leven: het middel om langer te leven?\\n...   \n",
       "3    30423159  Werken tot 65 jaar zorgt voor meer psychische ...   \n",
       "4    30423159  In 2012 is er een wet doorgekomen die het drag...   \n",
       "\n",
       "         BigFive  \n",
       "0  84-58-95-6-27  \n",
       "1   1-41-70-8-80  \n",
       "2   1-86-4-50-27  \n",
       "3   1-86-4-50-27  \n",
       "4   1-86-4-50-27  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "475"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['Openness', 'Conscientiousness', 'Extroversion', 'Agreeableness', 'Neuroticism']] = data.BigFive.str.split(pat= \"-\", expand = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminating NULL values\n",
    "data = data[data.BigFive != \"----\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 470 entries, 0 to 474\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   Participant        470 non-null    object\n",
      " 1   Essay              470 non-null    object\n",
      " 2   BigFive            470 non-null    object\n",
      " 3   Openness           470 non-null    object\n",
      " 4   Conscientiousness  470 non-null    object\n",
      " 5   Extroversion       470 non-null    object\n",
      " 6   Agreeableness      470 non-null    object\n",
      " 7   Neuroticism        470 non-null    object\n",
      "dtypes: object(8)\n",
      "memory usage: 33.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preprocessing will be defined as a single function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    \n",
    "    stoplist = stopwords.words('dutch') # define stop words\n",
    "    punctuations = string.punctuation + \"’¶•@°©®™\" # define punctuations\n",
    "    \n",
    "    txt = text.lower() # puts text in lowercase\n",
    "    txt = re.sub(r\"[^a-zA-ZÀ-ÿ]\", \" \", txt)\n",
    "    \n",
    "    translator = str.maketrans(punctuations, \" \"*len(punctuations))\n",
    "    s = txt.translate(translator)  # s is a variable that contains the data freed from punctuation\n",
    "    \n",
    "    no_digits= ''.join([i for i in s if not i.isdigit()])\n",
    "    cleaned = \" \".join(no_digits.split())\n",
    "    \n",
    "    word_tokens = word_tokenize(cleaned)\n",
    "    filtered_sentence = [w for w in word_tokens if not w in stoplist]\n",
    "    filtered_sentence = \" \".join(filtered_sentence)\n",
    "    \n",
    "    filtered_sentence = [stemmer.stem(word) for word in word_tokenize(filtered_sentence)]\n",
    "    filtered_sentence = \" \".join(filtered_sentence)\n",
    "    \n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Essay = data.Essay.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"clean_essay\"] = data.Essay.apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "470"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the cut-off points for our binary SVM to predict: if a certain personality \n",
    "# trait is 50 or higher, it will be assigned a 1, otherwise it will get a 0 if the value\n",
    "# is below\n",
    "\n",
    "\n",
    "ocean = [\"Openness\", \"Conscientiousness\", \"Extroversion\", \"Agreeableness\", \"Neuroticism\"]\n",
    "\n",
    "for column in ocean:\n",
    "    data[column] = data[column].astype(int)\n",
    "    data.loc[data[column] < 50, column] = 0\n",
    "    data.loc[data[column] >= 50, column] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant</th>\n",
       "      <th>Essay</th>\n",
       "      <th>BigFive</th>\n",
       "      <th>Openness</th>\n",
       "      <th>Conscientiousness</th>\n",
       "      <th>Extroversion</th>\n",
       "      <th>Agreeableness</th>\n",
       "      <th>Neuroticism</th>\n",
       "      <th>clean_essay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92419385</td>\n",
       "      <td>Het orgaandonorschap: een dualistische visie\\n...</td>\n",
       "      <td>84-58-95-6-27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>orgaandonorschap dualistisch visie donker hang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89353110</td>\n",
       "      <td>Iedereen automatisch geregistreerd als donor, ...</td>\n",
       "      <td>1-41-70-8-80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>iederen automatisch geregistreerd donor liever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30423159</td>\n",
       "      <td>Gezond leven: het middel om langer te leven?\\n...</td>\n",
       "      <td>1-86-4-50-27</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>gezond lev middel langer lev tijdschrift zoal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30423159</td>\n",
       "      <td>Werken tot 65 jaar zorgt voor meer psychische ...</td>\n",
       "      <td>1-86-4-50-27</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>werk jar zorgt psychisch problem over beslist ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30423159</td>\n",
       "      <td>In 2012 is er een wet doorgekomen die het drag...</td>\n",
       "      <td>1-86-4-50-27</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>wet doorgekom drag levensbeschouw teken verbie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Participant                                              Essay  \\\n",
       "0    92419385  Het orgaandonorschap: een dualistische visie\\n...   \n",
       "1    89353110  Iedereen automatisch geregistreerd als donor, ...   \n",
       "2    30423159  Gezond leven: het middel om langer te leven?\\n...   \n",
       "3    30423159  Werken tot 65 jaar zorgt voor meer psychische ...   \n",
       "4    30423159  In 2012 is er een wet doorgekomen die het drag...   \n",
       "\n",
       "         BigFive  Openness  Conscientiousness  Extroversion  Agreeableness  \\\n",
       "0  84-58-95-6-27         1                  1             1              0   \n",
       "1   1-41-70-8-80         0                  0             1              0   \n",
       "2   1-86-4-50-27         0                  1             0              1   \n",
       "3   1-86-4-50-27         0                  1             0              1   \n",
       "4   1-86-4-50-27         0                  1             0              1   \n",
       "\n",
       "   Neuroticism                                        clean_essay  \n",
       "0            0  orgaandonorschap dualistisch visie donker hang...  \n",
       "1            1  iederen automatisch geregistreerd donor liever...  \n",
       "2            0  gezond lev middel langer lev tijdschrift zoal ...  \n",
       "3            0  werk jar zorgt psychisch problem over beslist ...  \n",
       "4            0  wet doorgekom drag levensbeschouw teken verbie...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the data into a csv file so that we can reuse it in building the LSTM\n",
    "data.to_csv(\"./data/clean_data_ltp.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data splitting\n",
    "\n",
    "We will be splitting data into 80% train and 20% test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.20, random_state= 42) # any good reason why 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 376 observations; Test set: 94 observations\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set: {} observations; Test set: {} observations\".format(len(train), len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = [x for x in train.clean_essay]\n",
    "\n",
    "train_y_OPN = [x for x in train.Openness]\n",
    "train_y_CON = [x for x in train.Conscientiousness]\n",
    "train_y_EXT = [x for x in train.Extroversion]\n",
    "train_y_AGR = [x for x in train.Agreeableness]\n",
    "train_y_NEU = [x for x in train.Neuroticism]\n",
    "\n",
    "test_x = [x for x in test.clean_essay]\n",
    "\n",
    "test_y_OPN = [x for x in test.Openness]\n",
    "test_y_CON = [x for x in test.Conscientiousness]\n",
    "test_y_EXT = [x for x in test.Extroversion]\n",
    "test_y_AGR = [x for x in test.Agreeableness]\n",
    "test_y_NEU = [x for x in test.Neuroticism]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an SVM with a TF-IDF vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "train_x_vec = tfidf.fit_transform(train_x)\n",
    "test_x_vec = tfidf.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving our TF-IDF vocabulary, so that we can call it later\n",
    "pickle.dump(tfidf.vocabulary_, open(\"./tfidf_vocab/svm_vocab.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using GridSearchCV, we will conduct hyperparameter search to \n",
    "# determine the best parameters. Below we define the grid we are\n",
    "# searching in:\n",
    "\n",
    "grid = {\n",
    "    'C': [1,2,3,4,5,6,7,8,9,10,11,12],\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Openness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                           class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n",
       "                         'kernel': ['linear', 'rbf']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1_micro', verbose=0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First we will conduct the hyperparameter search\n",
    "\n",
    "OPN_model = svm.SVC()\n",
    "\n",
    "CV_svc = GridSearchCV(OPN_model, param_grid= grid, n_jobs =-1, scoring=\"f1_micro\")\n",
    "CV_svc.fit(train_x_vec, train_y_OPN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters for Openness: {'C': 3, 'kernel': 'rbf'}\n",
      "Best F1-score for Openness: 0.5477543859649123\n"
     ]
    }
   ],
   "source": [
    "print(\"Best hyperparameters for Openness: {}\".format(CV_svc.best_params_))\n",
    "print(\"Best F1-score for Openness: {}\".format(CV_svc.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score in detecting Open personality trait:  0.5638297872340425\n"
     ]
    }
   ],
   "source": [
    "# Next, we will train the SVMs on the gained values\n",
    "\n",
    "clf_svm_OPN = CV_svc.best_estimator_\n",
    "clf_svm_OPN.fit(train_x_vec, train_y_OPN)\n",
    "\n",
    "print(\"Accuracy score in detecting Open personality trait: \", clf_svm_OPN.score(test_x_vec, test_y_OPN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-micro: 0.5638\n",
      "Precision: 0.5000\n",
      "Recall: 0.5638\n"
     ]
    }
   ],
   "source": [
    "# Checking predictions over test data\n",
    "\n",
    "y_pred = clf_svm_OPN.predict(test_x_vec)\n",
    "\n",
    "print(\"F1-micro: {:.4f}\".format(f1_score(test_y_OPN, y_pred, average = \"micro\")))\n",
    "print(\"Precision: {:.4f}\".format(precision_score(test_y_OPN, y_pred)))\n",
    "print(\"Recall: {:.4f}\".format(recall_score(test_y_OPN, y_pred, average = \"micro\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.49      0.56        53\n",
      "           1       0.50      0.66      0.57        41\n",
      "\n",
      "    accuracy                           0.56        94\n",
      "   macro avg       0.57      0.57      0.56        94\n",
      "weighted avg       0.58      0.56      0.56        94\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Displaying the classification report:\n",
    "\n",
    "print(classification_report(test_y_OPN, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model to use in our pipeline\n",
    "\n",
    "model_path = \"./models/OPN_svm_model.pkl\"  \n",
    "with open(model_path, 'wb') as file:  \n",
    "    pickle.dump(clf_svm_OPN, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below the same process will be conducted over each of the remaining personality traits:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conscientiousness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                           class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n",
       "                         'kernel': ['linear', 'rbf']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1_micro', verbose=0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CON_model = svm.SVC()\n",
    "\n",
    "CV_svc = GridSearchCV(CON_model, param_grid=grid, n_jobs=-1, scoring=\"f1_micro\")\n",
    "CV_svc.fit(train_x_vec, train_y_CON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters for Conscientiousness: {'C': 1, 'kernel': 'rbf'}\n",
      "Best F1-score for Conscientiousness: 0.5401754385964913\n"
     ]
    }
   ],
   "source": [
    "print(\"Best hyperparameters for Conscientiousness: {}\".format(CV_svc.best_params_))\n",
    "print(\"Best F1-score for Conscientiousness: {}\".format(CV_svc.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score in detecting Conscientious personality trait:  0.4787234042553192\n"
     ]
    }
   ],
   "source": [
    "clf_svm_CON = CV_svc.best_estimator_\n",
    "clf_svm_CON.fit(train_x_vec, train_y_CON)\n",
    "\n",
    "print(\"Accuracy score in detecting Conscientious personality trait: \", clf_svm_OPN.score(test_x_vec, test_y_CON))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-micro: 0.5532\n",
      "Precision: 0.6667\n",
      "Recall: 0.5532\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf_svm_CON.predict(test_x_vec)\n",
    "\n",
    "print(\"F1-micro: {:.4f}\".format(f1_score(test_y_CON, y_pred, average = \"micro\")))\n",
    "print(\"Precision: {:.4f}\".format(precision_score(test_y_CON, y_pred)))\n",
    "print(\"Recall: {:.4f}\".format(recall_score(test_y_CON, y_pred, average = \"micro\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.84      0.64        45\n",
      "           1       0.67      0.29      0.40        49\n",
      "\n",
      "    accuracy                           0.55        94\n",
      "   macro avg       0.59      0.57      0.52        94\n",
      "weighted avg       0.60      0.55      0.52        94\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y_CON, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./models/CON_svm_model.pkl\"  \n",
    "with open(model_path, 'wb') as file:\n",
    "    pickle.dump(clf_svm_CON, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extroversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                           class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n",
       "                         'kernel': ['linear', 'rbf']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1_micro', verbose=0)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXT_model = svm.SVC()\n",
    "\n",
    "CV_svc = GridSearchCV(EXT_model, param_grid = grid, n_jobs= -1, scoring = \"f1_micro\")\n",
    "CV_svc.fit(train_x_vec,train_y_EXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters for Extroversion: {'C': 3, 'kernel': 'linear'}\n",
      "Best F1-score for Extroversion: 0.5744561403508772\n"
     ]
    }
   ],
   "source": [
    "print(\"Best hyperparameters for Extroversion: {}\".format(CV_svc.best_params_))\n",
    "print(\"Best F1-score for Extroversion: {}\".format(CV_svc.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of detecting Extroversion:  0.5212765957446809\n"
     ]
    }
   ],
   "source": [
    "clf_svm_EXT = CV_svc.best_estimator_\n",
    "clf_svm_EXT.fit(train_x_vec, train_y_EXT)\n",
    "\n",
    "print(\"Accuracy score of detecting Extroversion: \", clf_svm_EXT.score(test_x_vec, test_y_EXT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-micro: 0.5213\n",
      "Precision: 0.5833\n",
      "Recall: 0.5213\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf_svm_EXT.predict(test_x_vec)\n",
    "\n",
    "print(\"F1-micro: {:.4f}\".format(f1_score(test_y_EXT, y_pred, average = \"micro\")))\n",
    "print(\"Precision: {:.4f}\".format(precision_score(test_y_EXT, y_pred)))\n",
    "print(\"Recall: {:.4f}\".format(recall_score(test_y_EXT, y_pred, average = \"micro\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.51      0.48        41\n",
      "           1       0.58      0.53      0.55        53\n",
      "\n",
      "    accuracy                           0.52        94\n",
      "   macro avg       0.52      0.52      0.52        94\n",
      "weighted avg       0.53      0.52      0.52        94\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y_EXT, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./models/EXT_svm_model.pkl\"  \n",
    "with open(model_path, 'wb') as file:  \n",
    "    pickle.dump(clf_svm_EXT, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agreeableness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                           class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n",
       "                         'kernel': ['linear', 'rbf']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1_micro', verbose=0)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AGR_model = svm.SVC()\n",
    "\n",
    "CV_svc = GridSearchCV(AGR_model, param_grid = grid, n_jobs= -1, scoring = \"f1_micro\")\n",
    "CV_svc.fit(train_x_vec,train_y_AGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters for Agreeableness: {'C': 3, 'kernel': 'rbf'}\n",
      "Best F1-score for Agreeableness: 0.5718245614035088\n"
     ]
    }
   ],
   "source": [
    "print(\"Best hyperparameters for Agreeableness: {}\".format(CV_svc.best_params_))\n",
    "print(\"Best F1-score for Agreeableness: {}\".format(CV_svc.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of detecting Agreeableness:  0.43617021276595747\n"
     ]
    }
   ],
   "source": [
    "clf_svm_AGR = CV_svc.best_estimator_\n",
    "clf_svm_AGR.fit(train_x_vec, train_y_AGR)\n",
    "\n",
    "print(\"Accuracy score of detecting Agreeableness: \", clf_svm_AGR.score(test_x_vec, test_y_AGR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-micro: 0.4362\n",
      "Precision: 0.3226\n",
      "Recall: 0.4362\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf_svm_AGR.predict(test_x_vec)\n",
    "\n",
    "print(\"F1-micro: {:.4f}\".format(f1_score(test_y_AGR, y_pred, average = \"micro\")))\n",
    "print(\"Precision: {:.4f}\".format(precision_score(test_y_AGR, y_pred)))\n",
    "print(\"Recall: {:.4f}\".format(recall_score(test_y_AGR, y_pred, average = \"micro\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.60      0.54        52\n",
      "           1       0.32      0.24      0.27        42\n",
      "\n",
      "    accuracy                           0.44        94\n",
      "   macro avg       0.41      0.42      0.41        94\n",
      "weighted avg       0.42      0.44      0.42        94\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y_AGR, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./models/AGR_svm_model.pkl\"  \n",
    "with open(model_path, 'wb') as file:  \n",
    "    pickle.dump(clf_svm_AGR, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neuroticism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                           class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n",
       "                         'kernel': ['linear', 'rbf']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1_micro', verbose=0)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NEU_model = svm.SVC()\n",
    "\n",
    "CV_svc = GridSearchCV(NEU_model, param_grid = grid, n_jobs= -1, scoring = \"f1_micro\")\n",
    "CV_svc.fit(train_x_vec,train_y_NEU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters for Neuroticism are: {'C': 1, 'kernel': 'rbf'}\n",
      "Best F1-score for Neuroticism is: 0.51059649122807\n"
     ]
    }
   ],
   "source": [
    "print(\"Best hyperparameters for Neuroticism are: {}\".format(CV_svc.best_params_))\n",
    "print(\"Best F1-score for Neuroticism is: {}\".format(CV_svc.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of detecting Neuroticism:  0.4574468085106383\n"
     ]
    }
   ],
   "source": [
    "clf_svm_NEU = CV_svc.best_estimator_\n",
    "clf_svm_NEU.fit(train_x_vec, train_y_NEU)\n",
    "\n",
    "print(\"Accuracy score of detecting Neuroticism: \", clf_svm_NEU.score(test_x_vec, test_y_NEU))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-micro: 0.4574\n",
      "Precision: 0.5125\n",
      "Recall: 0.4574\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf_svm_NEU.predict(test_x_vec)\n",
    "\n",
    "print(\"F1-micro: {:.4f}\".format(f1_score(test_y_NEU, y_pred, average = \"micro\")))\n",
    "print(\"Precision: {:.4f}\".format(precision_score(test_y_NEU, y_pred)))\n",
    "print(\"Recall: {:.4f}\".format(recall_score(test_y_NEU, y_pred, average = \"micro\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.05      0.07        41\n",
      "           1       0.51      0.77      0.62        53\n",
      "\n",
      "    accuracy                           0.46        94\n",
      "   macro avg       0.33      0.41      0.34        94\n",
      "weighted avg       0.35      0.46      0.38        94\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y_NEU, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./models/NEU_svm_model.pkl\"  \n",
    "with open(model_path, 'wb') as file:  \n",
    "    pickle.dump(clf_svm_NEU, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Composing an SVM prediction pipeline with all personalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_vec = TfidfVectorizer(decode_error=\"replace\", vocabulary=pickle.load(open(\"./tfidf_vocab/svm_vocab.pkl\", \"rb\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_big_five(essay): \n",
    "    path = \"./models/\"\n",
    "    extension = \"_svm_model.pkl\"\n",
    "    \n",
    "    with open(path+\"AGR\"+extension, 'rb') as file:  \n",
    "        AGR_model = pickle.load(file)\n",
    "    \n",
    "    with open(path+\"CON\"+extension, 'rb') as file:  \n",
    "        CON_model = pickle.load(file)\n",
    "    \n",
    "    with open(path+\"EXT\"+extension, 'rb') as file:  \n",
    "        EXT_model = pickle.load(file)\n",
    "    \n",
    "    with open(path+\"NEU\"+extension, 'rb') as file:  \n",
    "        NEU_model = pickle.load(file)\n",
    "    \n",
    "    with open(path+\"OPN\"+extension, 'rb') as file:  \n",
    "        OPN_model = pickle.load(file)\n",
    "    \n",
    "    # building a feature matrix:\n",
    "    transformer = TfidfTransformer()\n",
    "    features = transformer.fit_transform(loaded_vec.fit_transform([preprocess(essay)]))\n",
    "    \n",
    "    # getting all 5 predictions:\n",
    "    \n",
    "    AGR_prediction = int(AGR_model.predict(features.toarray()))\n",
    "    CON_prediction = int(CON_model.predict(features.toarray()))\n",
    "    EXT_prediction = int(EXT_model.predict(features.toarray()))\n",
    "    NEU_prediction = int(NEU_model.predict(features.toarray()))\n",
    "    OPN_prediction = int(OPN_model.predict(features.toarray()))\n",
    "    \n",
    "    # reporting on all 5 predictions in one report:\n",
    "    final_prediction = {\n",
    "        \"Openness\": OPN_prediction,\n",
    "        \"Conscientiousness\": CON_prediction,\n",
    "        \"Extroversion\": EXT_prediction,\n",
    "        \"Agreeableness\": AGR_prediction,\n",
    "        \"Neuroticism\": NEU_prediction\n",
    "    }\n",
    "    \n",
    "    return final_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Openness': 1,\n",
       " 'Conscientiousness': 0,\n",
       " 'Extroversion': 1,\n",
       " 'Agreeableness': 0,\n",
       " 'Neuroticism': 1}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_essay = data.Essay[13]\n",
    "result = predict_big_five(test_essay)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Above we provided a possible solution for assembling a binary SVM pipeline to predict Big Five personality traits in the Dutch language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "specialkernel",
   "language": "python",
   "name": "specialkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
