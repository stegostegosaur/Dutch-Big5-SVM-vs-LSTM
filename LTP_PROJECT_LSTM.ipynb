{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM\n",
    "\n",
    "By\n",
    "\n",
    "A.Ntoumi & A. Steger (University of Groningen, Language Technology Project 2019-20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import random\n",
    "from pprint import pprint\n",
    "import statistics\n",
    "from collections import Counter\n",
    "import re\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "stemmer = SnowballStemmer(\"dutch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "essays_df = pd.read_csv(\"./data/clean_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>essay</th>\n",
       "      <th>personality</th>\n",
       "      <th>Openness</th>\n",
       "      <th>Conscientiousness</th>\n",
       "      <th>Extroversion</th>\n",
       "      <th>Agreeableness</th>\n",
       "      <th>Neuroticism</th>\n",
       "      <th>clean_essay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>56610387</td>\n",
       "      <td>Het is niet enkel algemeen geweten, het is ook...</td>\n",
       "      <td>12-35-70-38-49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>enkel algemen gewet bewez bevind anno sted wei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>12570386</td>\n",
       "      <td>Alweer reclame? En het programma is nog maar n...</td>\n",
       "      <td>84-83-64-69-55</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>alwer reclam programma net begonn zin twijfel ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>10289345</td>\n",
       "      <td>Van welvaartstoename tot psychische neerval\\n\\...</td>\n",
       "      <td>65-58-48-38-80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>welvaartstoenam psychisch neerval belgie stat ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                                              essay  \\\n",
       "200  56610387  Het is niet enkel algemeen geweten, het is ook...   \n",
       "413  12570386  Alweer reclame? En het programma is nog maar n...   \n",
       "77   10289345  Van welvaartstoename tot psychische neerval\\n\\...   \n",
       "\n",
       "        personality  Openness  Conscientiousness  Extroversion  Agreeableness  \\\n",
       "200  12-35-70-38-49         0                  0             1              0   \n",
       "413  84-83-64-69-55         1                  1             1              1   \n",
       "77   65-58-48-38-80         1                  1             0              0   \n",
       "\n",
       "     Neuroticism                                        clean_essay  \n",
       "200            0  enkel algemen gewet bewez bevind anno sted wei...  \n",
       "413            1  alwer reclam programma net begonn zin twijfel ...  \n",
       "77             1  welvaartstoenam psychisch neerval belgie stat ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show a sample of the loaded dataset\n",
    "essays_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 470 entries, 0 to 469\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   user_id            470 non-null    int64 \n",
      " 1   essay              470 non-null    object\n",
      " 2   personality        470 non-null    object\n",
      " 3   Openness           470 non-null    int64 \n",
      " 4   Conscientiousness  470 non-null    int64 \n",
      " 5   Extroversion       470 non-null    int64 \n",
      " 6   Agreeableness      470 non-null    int64 \n",
      " 7   Neuroticism        470 non-null    int64 \n",
      " 8   clean_essay        470 non-null    object\n",
      "dtypes: int64(6), object(3)\n",
      "memory usage: 33.2+ KB\n"
     ]
    }
   ],
   "source": [
    "essays_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above dataset is already preprocessed in the SVM notebook, thus we can directly exploit the `clean_essay` document and the `personalities` features to build our LSTM model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dictionaries and encode essays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the list of tokens we have in the essays corpus\n",
    "all_words = ' '.join(essays_df.clean_essay.tolist())\n",
    "\n",
    "#counting the word frequencies in the essay corpus\n",
    "word_counts = Counter(all_words.split())\n",
    "\n",
    "# sorted word list according to descending order\n",
    "word_list = sorted(word_counts, key = word_counts.get, reverse = True)\n",
    "\n",
    "# creating two dictionaries to map word to index, and map index to word.\n",
    "word_to_index = {word:idx+1 for idx,word in enumerate(word_list)}\n",
    "index_to_word = {idx+1:word for idx,word in enumerate(word_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_to_index sample dict :\n",
      "\n",
      "{'gaybashingtr': 15325,\n",
      " 'gebruikt': 161,\n",
      " 'gerold': 12705,\n",
      " 'gesabotteeerd': 12554,\n",
      " 'ieder': 322,\n",
      " 'losstond': 13829,\n",
      " 'omschol': 4911,\n",
      " 'productiev': 15873,\n",
      " 'verdubbel': 7236,\n",
      " 'woordbegrip': 5380}\n",
      "\n",
      "index_to_word sample dict :\n",
      "\n",
      "{50: 'belangrijk',\n",
      " 59: 'bijvoorbeeld',\n",
      " 2519: 'opgegroeid',\n",
      " 5204: 'representatief',\n",
      " 6197: 'rub',\n",
      " 6373: 'stolt',\n",
      " 9065: 'stramien',\n",
      " 9196: 'fmri',\n",
      " 12713: 'prijkt',\n",
      " 14871: 'begrafeniskost'}\n"
     ]
    }
   ],
   "source": [
    "# samples:\n",
    "print(\"word_to_index sample dict :\\n\")\n",
    "pprint(dict(random.sample(word_to_index.items(), 10)))\n",
    "print(\"\\nindex_to_word sample dict :\\n\")\n",
    "pprint(dict(random.sample(index_to_word.items(), 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding essays\n",
    "encoded_essays = [[word_to_index[word] for word in essay.split()] for essay in essays_df['clean_essay']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will encode the labels for all the Big Five personality traits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_OPN_labels = essays_df['Openness'].values\n",
    "encoded_CON_labels = essays_df['Conscientiousness'].values\n",
    "encoded_EXT_labels = essays_df['Extroversion'].values\n",
    "encoded_AGR_labels = essays_df['Agreeableness'].values\n",
    "encoded_NEU_labels = essays_df['Neuroticism'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assering that length of essays be equal to length of labels\n",
    "assert len(encoded_essays) == len(encoded_EXT_labels),\"Number of of encoded essays and encoded labels should be same\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding essays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we need to make the essays of the same length, so we will use padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2196, 1958, 1786, 1735, 1650, 1594, 1493, 1472, 1470, 1463, 1434, 1430, 1420, 1404, 1394, 1344, 1329, 1325, 1325, 1322]\n"
     ]
    }
   ],
   "source": [
    "# printing top 20 max length\n",
    "len_max = ([len(x) for x in encoded_essays])\n",
    "print(sorted(list(len_max), reverse=True)[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get the right padding from the list of essay lengths above, we will use the median statistical function to get the right padding value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The median of the essays lengths distributions is 362.0\n"
     ]
    }
   ],
   "source": [
    "print(\"The median of the essays lengths distributions is {}\".format(statistics.median(len_max)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like the median of essay length is 362 words so a standard size of 400 should be enough to get all the features of an essay (especially because we assume that people will have expressed how they feel in their first 300 words). By fixing a standard essay size of 400, short essays will be padded with zeros and long ones will be truncated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to pad our encoded essays/feature\n",
    "def pad_features(essays, max_length):\n",
    "    \"\"\"\n",
    "    Returns features of reviews where each review is padded with 0's or truncated to the max_length\n",
    "    \"\"\"\n",
    "    \n",
    "    features = []\n",
    "    \n",
    "    # pad or truncate each review\n",
    "    for idx, row in enumerate(essays):\n",
    "        if len(row) >= max_length:\n",
    "            features.append(row[:max_length])\n",
    "        else:\n",
    "            features.append(np.concatenate((np.zeros(max_length-len(row)), np.array(row))))\n",
    "        \n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1., 2., 3., 4.],\n",
       "       [1., 2., 3., 4., 5., 6., 7., 8.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a simple sanity check\n",
    "test_array = [[1,2,3,4],\n",
    "    [1,2,3,4,5,6,7,8,9,10]]\n",
    "\n",
    "# pad the test_array to a maximum size of 8\n",
    "pad_features(test_array,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving under a new variable:\n",
    "padded_features = pad_features(essays = encoded_essays, max_length = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if the number of feature is equal to number of reviews we passed\n",
    "assert len(padded_features) == len(encoded_essays),\"Length Mismatch after padding\"\n",
    "assert len(padded_features[0]) == 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the total length of essays in the features\n",
    "total = padded_features.shape[0]\n",
    "# set the train size to 0.8\n",
    "train_ratio = 0.8\n",
    "\n",
    "# we will use 80% of the data for training and use remaining 20% for testing and validation\n",
    "# we will split the remaining 20% into half and separate into them testing and validation sets\n",
    "train_idx = int(total*0.8)\n",
    "train_x, remaining_x  = padded_features[:train_idx], padded_features[train_idx:]\n",
    "\n",
    "# doing the same for labels \n",
    "train_y_OPN, remaining_y_OPN = encoded_OPN_labels[:train_idx], encoded_OPN_labels[train_idx:]\n",
    "train_y_CON, remaining_y_CON = encoded_CON_labels[:train_idx], encoded_CON_labels[train_idx:]\n",
    "train_y_EXT, remaining_y_EXT = encoded_EXT_labels[:train_idx], encoded_EXT_labels[train_idx:]\n",
    "train_y_AGR, remaining_y_AGR = encoded_AGR_labels[:train_idx], encoded_AGR_labels[train_idx:]\n",
    "train_y_NEU, remaining_y_NEU = encoded_NEU_labels[:train_idx], encoded_NEU_labels[train_idx:]\n",
    "\n",
    "\n",
    "# splitting the remaining 20% to validation and testing\n",
    "test_idx = int(len(remaining_x)*0.5)\n",
    "test_x, valid_x  = remaining_x[:test_idx], remaining_x[test_idx:]\n",
    "\n",
    "# doing the same for labels\n",
    "test_y_OPN, valid_y_OPN = remaining_y_OPN[:test_idx], remaining_y_OPN[test_idx:]\n",
    "test_y_CON, valid_y_CON = remaining_y_CON[:test_idx], remaining_y_CON[test_idx:]\n",
    "test_y_EXT, valid_y_EXT = remaining_y_EXT[:test_idx], remaining_y_EXT[test_idx:]\n",
    "test_y_AGR, valid_y_AGR = remaining_y_AGR[:test_idx], remaining_y_AGR[test_idx:]\n",
    "test_y_NEU, valid_y_NEU = remaining_y_NEU[:test_idx], remaining_y_NEU[test_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t Features Shape\n",
      "Train Set:\t\t(376, 400) \n",
      "Validation Set:\t\t(47, 400) \n",
      "Testing Set\t\t(47, 400)\n"
     ]
    }
   ],
   "source": [
    "# let us see the shape of our training, validation and testing data\n",
    "print(\"\\t\\t\\t Features Shape\")\n",
    "print(\"Train Set:\\t\\t{}\".format(train_x.shape),\n",
    "     \"\\nValidation Set:\\t\\t{}\".format(valid_x.shape),\n",
    "     \"\\nTesting Set\\t\\t{}\".format(test_x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t Label Shape\n",
      "Train Set:\t\t(376,) \n",
      "Validation Set:\t\t(47,) \n",
      "Testing Set\t\t(47,)\n"
     ]
    }
   ],
   "source": [
    "#let us see the shape of labels for out training, validation and testing data\n",
    "print(\"\\t\\t\\t Label Shape\")\n",
    "print(\"Train Set:\\t\\t{}\".format(train_y_OPN.shape),\n",
    "     \"\\nValidation Set:\\t\\t{}\".format(valid_y_OPN.shape),\n",
    "     \"\\nTesting Set\\t\\t{}\".format(test_y_OPN.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data After preprocessing: \n",
      "Features:(470, 400)\n",
      "Labels:(470,)\n"
     ]
    }
   ],
   "source": [
    "print('Total data After preprocessing: \\nFeatures:{}\\nLabels:{}'.format(padded_features.shape, encoded_OPN_labels.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset and batching into DataLoaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use TensorDataset and DataLoader for this purpose. TensorDataset takes features and labels with same dimension and creates a dataset, and DataLoader turns both features and labels in batch sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Openness prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create TensorDatasets\n",
    "train_data_OPN = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y_OPN))\n",
    "valid_data_OPN = TensorDataset(torch.from_numpy(valid_x), torch.from_numpy(valid_y_OPN))\n",
    "test_data_OPN =  TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y_OPN))\n",
    "\n",
    "# set the batch size\n",
    "batch_size = 47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffling the data\n",
    "train_loader_OPN = DataLoader(train_data_OPN, shuffle=True, batch_size=batch_size, drop_last=False)\n",
    "valid_loader_OPN = DataLoader(valid_data_OPN, shuffle=True, batch_size=batch_size, drop_last=False)\n",
    "test_loader_OPN = DataLoader(test_data_OPN, shuffle=True, batch_size=batch_size, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size:torch.Size([47, 400])\n",
      "Sample Input:\n",
      "tensor([[1.6920e+03, 5.2000e+01, 3.6600e+02,  ..., 5.6100e+02, 5.3000e+01,\n",
      "         1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.4200e+02, 9.6200e+02,\n",
      "         6.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.5000e+01, 9.7000e+01,\n",
      "         4.9900e+02],\n",
      "        ...,\n",
      "        [1.5100e+02, 5.0000e+00, 3.9700e+02,  ..., 5.8000e+01, 3.0000e+00,\n",
      "         1.7700e+02],\n",
      "        [2.2000e+01, 1.0950e+03, 1.0950e+03,  ..., 1.4800e+02, 1.1969e+04,\n",
      "         2.2000e+01],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 7.2500e+02, 1.0000e+01,\n",
      "         1.3020e+03]], dtype=torch.float64)\n",
      "\n",
      "Sample Label size:torch.Size([47])\n",
      "Sample Label:\n",
      "tensor([1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1,\n",
      "        0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "# visualizing a batch of our training data\n",
    "dataiter = iter(train_loader_OPN)\n",
    "sample_x, sample_y = dataiter.next()\n",
    "\n",
    "print('Sample input size:{}'.format(sample_x.size()))\n",
    "print('Sample Input:\\n{}\\n'.format(sample_x))\n",
    "print('Sample Label size:{}'.format(sample_y.size()))\n",
    "print('Sample Label:\\n{}'.format(sample_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining our LTSM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on CPU\n"
     ]
    }
   ],
   "source": [
    "# checking if GPU is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "if train_on_gpu:\n",
    "    print('Training on GPU')\n",
    "else:\n",
    "    print(\"Training on CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class PersonalityLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    The RNN model that will be used to perform sentiment analysis\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
    "        \"\"\"\n",
    "        Initializing the model by setting up the layers\n",
    "        \"\"\"\n",
    "        super(PersonalityLSTM, self).__init__()\n",
    "\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # embedding and LSTM layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
    "                            dropout=drop_prob, batch_first=True)\n",
    "        \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # linear and sigmoid layers\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        Defining forward pass function\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # embeddings and lstm_out\n",
    "        x = x.long()\n",
    "        embeds = self.embedding(x)\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "    \n",
    "        # stack up lstm outputs\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "        # dropout and fully connected layer\n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        # sigmoid function\n",
    "        sig_out = self.sig(out)\n",
    "        \n",
    "        # reshape to batch_size first\n",
    "        sig_out = sig_out.view(batch_size, -1)\n",
    "        sig_out = sig_out[:, -1] \n",
    "        \n",
    "        # returns last sigmoid output and hidden state\n",
    "        return sig_out, hidden\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Creates two new tensors with a size of number of layers * batch size * hidden layers\n",
    "        # Initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate the network\n",
    "\n",
    "We will continue with instantiating the network. First, let us define the hyperparameters\n",
    "\n",
    "* `vocab_size`: Size of our vocabulary or the range of values for our input.\n",
    "* `output_size`: Size of our desired output: the number of class scores we want to output (here 1: if trait belongs to a subject and 0: if it does not)\n",
    "* `embedding_dim`: Number of columns in the embedding lookup table; size of our embeddings\n",
    "* `hidden_dim`: Number of units in the hidden layers of our LSTM cells. We have decided to go by 256\n",
    "* `n_layers`: Number of LSTM layers in the network. This value is typically between 1-3, we have opted for 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PersonalityLSTM(\n",
      "  (embedding): Embedding(20461, 400)\n",
      "  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sig): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# instantiating our model with hyperparameters\n",
    "\n",
    "vocab_size = len(word_to_index) + 2\n",
    "output_size = 1\n",
    "embedding_dim = 400\n",
    "hidden_dim = 256\n",
    "n_layers = 2\n",
    "\n",
    "net = PersonalityLSTM(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the learning rate to 0.001\n",
    "lr = 0.001\n",
    "\n",
    "# loss and optimization functions\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "# save path to save our weights with best validation accuracy\n",
    "save_OPN_path = './models/best_validation_OPN.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "def train(model, criterion, optimizer, train_loader, valid_loader, batch_size, train_on_gpu, save_path):\n",
    "    valid_loss_min = np.Inf\n",
    "        \n",
    "    epochs = 4 \n",
    "\n",
    "    counter = 0\n",
    "    print_every = 10\n",
    "    clip=5 # gradient clipping to avoid exploding gradients\n",
    "\n",
    "    # move model to GPU, if available\n",
    "    if(train_on_gpu):\n",
    "        model.cuda()\n",
    "\n",
    "    model.train()\n",
    "    # train for some number of epochs\n",
    "    for e in range(epochs):\n",
    "        # initialize hidden state\n",
    "        h = model.init_hidden(batch_size)\n",
    "\n",
    "        # batch loop\n",
    "        for inputs, labels in train_loader:\n",
    "            counter += 1\n",
    "            if(train_on_gpu):\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "            # Creating new variables for the hidden state to\n",
    "            # avoid backpropagation through the entire training history\n",
    "            h = tuple([each.data for each in h])\n",
    "\n",
    "            # zero accumulated gradients\n",
    "            model.zero_grad()\n",
    "\n",
    "            # get the output from the model\n",
    "            output, h = model(inputs, h)\n",
    "\n",
    "            # calculate the loss and perform backpropagation\n",
    "            loss = criterion(output.squeeze(), labels.float())\n",
    "            loss.backward()\n",
    "\n",
    "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "            optimizer.step()\n",
    "\n",
    "            # loss stats\n",
    "            if counter % print_every == 0:\n",
    "                # Get validation loss\n",
    "                val_h = net.init_hidden(batch_size)\n",
    "                val_losses = []\n",
    "                net.eval()\n",
    "                \n",
    "                for inputs, labels in valid_loader:\n",
    "\n",
    "                # Creating new variables for the hidden state to\n",
    "                # avoid backpropagation through the entire training history\n",
    "                    val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "                    if(train_on_gpu):\n",
    "                        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "                    output, val_h = model(inputs, val_h)\n",
    "                    val_loss = criterion(output.squeeze(), labels.float())\n",
    "\n",
    "                    val_losses.append(val_loss.item())\n",
    "\n",
    "                model.train()\n",
    "\n",
    "                # saving the model with best validation accuracy. \n",
    "                if np.mean(val_losses) <= valid_loss_min:\n",
    "                    print('Validation loss decreased ({:.6f} ---------> {:.6f}).\\t Saving model...'.\n",
    "                          format(valid_loss_min, np.mean(val_losses)))\n",
    "                    torch.save(model.state_dict(), save_path)\n",
    "                    valid_loss_min = np.mean(val_losses)\n",
    "\n",
    "                print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                      \"Step: {}...\".format(counter),\n",
    "                      \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                      \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf ---------> 0.694335).\t Saving model...\n",
      "Epoch: 2/4... Step: 10... Loss: 0.663769... Val Loss: 0.694335\n",
      "Epoch: 3/4... Step: 20... Loss: 0.450650... Val Loss: 0.697766\n",
      "Epoch: 4/4... Step: 30... Loss: 0.216449... Val Loss: 0.954250\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "train(model=net, criterion=criterion, optimizer=optimizer, train_loader=train_loader_OPN, valid_loader=valid_loader_OPN, batch_size=batch_size, train_on_gpu=train_on_gpu, save_path=save_OPN_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model that got the best validation accuracy\n",
    "net.load_state_dict(torch.load(save_OPN_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, criterion, test_loader, batch_size, train_on_gpu):\n",
    "    \"\"\"\n",
    "    Tests and returns the accuracy and loss of the given model on the given dataset\n",
    "    \"\"\"\n",
    "    test_losses = [] # track loss\n",
    "    num_correct = 0\n",
    "    \n",
    "    # initial hidden state\n",
    "    h = model.init_hidden(batch_size)\n",
    "    net.eval() # turning of back propagation\n",
    "    \n",
    "    #iterating over test data\n",
    "    for inputs, labels in test_loader:\n",
    "        # Creating new variables for the hidden state to\n",
    "        # avoid backpropagation through the entire training history\n",
    "        h = tuple([each.data for each in h])\n",
    "        \n",
    "        if train_on_gpu:\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            \n",
    "        #get predicted outputs\n",
    "        output, h = net(inputs, h)\n",
    "        \n",
    "        #calculate loss\n",
    "        test_loss = criterion(output.squeeze(), labels.float())\n",
    "        test_losses.append(test_loss.item())\n",
    "        \n",
    "        # convert the output probabilities to predicted class( 0 or 1)\n",
    "        pred = torch.round(output.squeeze()) # rounds to nearest integer\n",
    "        \n",
    "        # compare prediction to true label\n",
    "        correct_tensor = pred.eq(labels.float().view_as(pred))\n",
    "        correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "        num_correct += np.sum(correct)\n",
    "    \n",
    "    # printing stats\n",
    "    print('Test loss: {:.3f}'.format(np.mean(test_losses)))\n",
    "    \n",
    "    #accuracy over all test_data\n",
    "    test_acc = num_correct/len(test_loader.dataset)\n",
    "    print(\"Test accuracy: {:.3f} %\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.688\n",
      "Test accuracy: 0.574 %\n"
     ]
    }
   ],
   "source": [
    "# testing performance of our model\n",
    "test(model=net, criterion=criterion, test_loader=test_loader_OPN, batch_size=batch_size, train_on_gpu=train_on_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Conscientiousness prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_CON = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y_CON))\n",
    "valid_data_CON = TensorDataset(torch.from_numpy(valid_x), torch.from_numpy(valid_y_CON))\n",
    "test_data_CON =  TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y_CON))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_CON = DataLoader(train_data_CON, shuffle=True, batch_size=batch_size, drop_last=False)\n",
    "valid_loader_CON = DataLoader(valid_data_CON, shuffle=True, batch_size=batch_size, drop_last=False)\n",
    "test_loader_CON = DataLoader(test_data_CON, shuffle=True, batch_size=batch_size, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size:torch.Size([47, 400])\n",
      "Sample Input:\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.6920e+03, 4.4850e+03,\n",
      "         3.4990e+03],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00, 2.9400e+02,\n",
      "         1.7400e+02],\n",
      "        [3.4000e+01, 6.1000e+01, 2.2270e+03,  ..., 3.1000e+01, 4.8900e+02,\n",
      "         2.7000e+01],\n",
      "        ...,\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.5700e+02, 1.0200e+02,\n",
      "         4.1300e+02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.1680e+03, 9.0000e+00,\n",
      "         4.5740e+03],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00, 5.0000e+00,\n",
      "         1.6120e+03]], dtype=torch.float64)\n",
      "\n",
      "Sample Label size:torch.Size([47])\n",
      "Sample Label:\n",
      "tensor([0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0,\n",
      "        1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader_CON)\n",
    "sample_x, sample_y = dataiter.next()\n",
    "\n",
    "print('Sample input size:{}'.format(sample_x.size()))\n",
    "print('Sample Input:\\n{}\\n'.format(sample_x))\n",
    "print('Sample Label size:{}'.format(sample_y.size()))\n",
    "print('Sample Label:\\n{}'.format(sample_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_CON_path = './models/best_validation_CON.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf ---------> 0.707953).\t Saving model...\n",
      "Epoch: 2/4... Step: 10... Loss: 0.701135... Val Loss: 0.707953\n",
      "Epoch: 3/4... Step: 20... Loss: 0.518467... Val Loss: 0.739995\n",
      "Epoch: 4/4... Step: 30... Loss: 0.301660... Val Loss: 0.915529\n"
     ]
    }
   ],
   "source": [
    "train(model=net, criterion=criterion, optimizer=optimizer, train_loader=train_loader_CON, valid_loader=valid_loader_CON, batch_size=batch_size, train_on_gpu=train_on_gpu, save_path=save_CON_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(torch.load(save_CON_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.701\n",
      "Test accuracy: 0.468 %\n"
     ]
    }
   ],
   "source": [
    "test(model=net, criterion=criterion, test_loader=test_loader_CON, batch_size=batch_size, train_on_gpu=train_on_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Extroversion prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_EXT = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y_EXT))\n",
    "valid_data_EXT = TensorDataset(torch.from_numpy(valid_x), torch.from_numpy(valid_y_EXT))\n",
    "test_data_EXT =  TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y_EXT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_EXT = DataLoader(train_data_EXT, shuffle=True, batch_size=batch_size, drop_last=False)\n",
    "valid_loader_EXT = DataLoader(valid_data_EXT, shuffle=True, batch_size=batch_size, drop_last=False)\n",
    "test_loader_EXT = DataLoader(test_data_EXT, shuffle=True, batch_size=batch_size, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size:torch.Size([47, 400])\n",
      "Sample Input:\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 8.9000e+01, 2.8310e+03,\n",
      "         5.3000e+01],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.0000e+01, 4.4800e+02,\n",
      "         3.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.3100e+02, 1.4550e+03,\n",
      "         3.1140e+03],\n",
      "        ...,\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.4200e+02, 9.6200e+02,\n",
      "         6.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.4004e+04, 1.5610e+03,\n",
      "         9.3800e+03],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.3000e+01, 2.2800e+02,\n",
      "         1.1200e+02]], dtype=torch.float64)\n",
      "\n",
      "Sample Label size:torch.Size([47])\n",
      "Sample Label:\n",
      "tensor([0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1,\n",
      "        1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader_EXT)\n",
    "sample_x, sample_y = dataiter.next()\n",
    "\n",
    "print('Sample input size:{}'.format(sample_x.size()))\n",
    "print('Sample Input:\\n{}\\n'.format(sample_x))\n",
    "print('Sample Label size:{}'.format(sample_y.size()))\n",
    "print('Sample Label:\\n{}'.format(sample_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_EXT_path = './models/best_validation_EXT.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf ---------> 0.721867).\t Saving model...\n",
      "Epoch: 2/4... Step: 10... Loss: 0.662397... Val Loss: 0.721867\n",
      "Epoch: 3/4... Step: 20... Loss: 0.452118... Val Loss: 0.896608\n",
      "Epoch: 4/4... Step: 30... Loss: 0.236388... Val Loss: 1.450716\n"
     ]
    }
   ],
   "source": [
    "train(model=net, criterion=criterion, optimizer=optimizer, train_loader=train_loader_EXT, valid_loader=valid_loader_EXT, batch_size=batch_size, train_on_gpu=train_on_gpu, save_path=save_EXT_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(torch.load(save_EXT_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.697\n",
      "Test accuracy: 0.553 %\n"
     ]
    }
   ],
   "source": [
    "test(model=net, criterion=criterion, test_loader=test_loader_EXT, batch_size=batch_size, train_on_gpu=train_on_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Agreeableness prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_AGR = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y_AGR))\n",
    "valid_data_AGR = TensorDataset(torch.from_numpy(valid_x), torch.from_numpy(valid_y_AGR))\n",
    "test_data_AGR =  TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y_AGR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_AGR = DataLoader(train_data_AGR, shuffle=True, batch_size=batch_size, drop_last=False)\n",
    "valid_loader_AGR = DataLoader(valid_data_AGR, shuffle=True, batch_size=batch_size, drop_last=False)\n",
    "test_loader_AGR = DataLoader(test_data_AGR, shuffle=True, batch_size=batch_size, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size:torch.Size([47, 400])\n",
      "Sample Input:\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 7.3200e+02, 1.2050e+03,\n",
      "         1.1080e+03],\n",
      "        [1.0000e+00, 8.8000e+01, 6.1000e+01,  ..., 1.1520e+03, 1.1520e+03,\n",
      "         2.4200e+02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.9000e+01, 3.4990e+03,\n",
      "         7.6300e+02],\n",
      "        ...,\n",
      "        [1.7995e+04, 7.0000e+00, 1.2200e+02,  ..., 6.5300e+02, 7.2000e+02,\n",
      "         4.3100e+02],\n",
      "        [1.6550e+03, 8.3000e+01, 1.8900e+02,  ..., 9.7800e+02, 1.5740e+03,\n",
      "         3.2100e+02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.9900e+02, 1.7430e+03,\n",
      "         6.9000e+01]], dtype=torch.float64)\n",
      "\n",
      "Sample Label size:torch.Size([47])\n",
      "Sample Label:\n",
      "tensor([0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
      "        0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader_AGR)\n",
    "sample_x, sample_y = dataiter.next()\n",
    "\n",
    "print('Sample input size:{}'.format(sample_x.size()))\n",
    "print('Sample Input:\\n{}\\n'.format(sample_x))\n",
    "print('Sample Label size:{}'.format(sample_y.size()))\n",
    "print('Sample Label:\\n{}'.format(sample_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_AGR_path = './models/best_validation_AGR.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf ---------> 0.736247).\t Saving model...\n",
      "Epoch: 2/4... Step: 10... Loss: 0.532577... Val Loss: 0.736247\n",
      "Epoch: 3/4... Step: 20... Loss: 0.345809... Val Loss: 0.826437\n",
      "Epoch: 4/4... Step: 30... Loss: 0.170313... Val Loss: 1.058094\n"
     ]
    }
   ],
   "source": [
    "train(model=net, criterion=criterion, optimizer=optimizer, train_loader=train_loader_AGR, valid_loader=valid_loader_AGR, batch_size=batch_size, train_on_gpu=train_on_gpu, save_path=save_AGR_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(torch.load(save_AGR_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.666\n",
      "Test accuracy: 0.617 %\n"
     ]
    }
   ],
   "source": [
    "test(model=net, criterion=criterion, test_loader=test_loader_AGR, batch_size=batch_size, train_on_gpu=train_on_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Neuroticism prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_NEU = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y_NEU))\n",
    "valid_data_NEU = TensorDataset(torch.from_numpy(valid_x), torch.from_numpy(valid_y_NEU))\n",
    "test_data_NEU =  TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y_NEU))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_NEU = DataLoader(train_data_NEU, shuffle=True, batch_size=batch_size, drop_last=False)\n",
    "valid_loader_NEU = DataLoader(valid_data_NEU, shuffle=True, batch_size=batch_size, drop_last=False)\n",
    "test_loader_NEU = DataLoader(test_data_NEU, shuffle=True, batch_size=batch_size, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size:torch.Size([47, 400])\n",
      "Sample Input:\n",
      "tensor([[5.5800e+02, 1.0000e+00, 4.2270e+03,  ..., 2.0000e+02, 4.3900e+02,\n",
      "         4.3290e+03],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 5.1200e+02, 5.2000e+01,\n",
      "         4.1000e+02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.0000e+00, 1.6740e+03,\n",
      "         6.4800e+02],\n",
      "        ...,\n",
      "        [3.1000e+01, 2.7800e+02, 5.7900e+02,  ..., 4.0160e+03, 3.0890e+03,\n",
      "         5.5810e+03],\n",
      "        [4.3600e+02, 5.2700e+02, 5.3000e+01,  ..., 1.1790e+03, 1.0050e+03,\n",
      "         5.0930e+03],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.4510e+03, 7.2000e+01,\n",
      "         2.3500e+02]], dtype=torch.float64)\n",
      "\n",
      "Sample Label size:torch.Size([47])\n",
      "Sample Label:\n",
      "tensor([1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1,\n",
      "        0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader_NEU)\n",
    "sample_x, sample_y = dataiter.next()\n",
    "\n",
    "print('Sample input size:{}'.format(sample_x.size()))\n",
    "print('Sample Input:\\n{}\\n'.format(sample_x))\n",
    "print('Sample Label size:{}'.format(sample_y.size()))\n",
    "print('Sample Label:\\n{}'.format(sample_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_NEU_path = './models/best_validation_NEU.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf ---------> 0.695801).\t Saving model...\n",
      "Epoch: 2/4... Step: 10... Loss: 0.696556... Val Loss: 0.695801\n",
      "Validation loss decreased (0.695801 ---------> 0.677939).\t Saving model...\n",
      "Epoch: 3/4... Step: 20... Loss: 0.627210... Val Loss: 0.677939\n",
      "Validation loss decreased (0.677939 ---------> 0.676995).\t Saving model...\n",
      "Epoch: 4/4... Step: 30... Loss: 0.459556... Val Loss: 0.676995\n"
     ]
    }
   ],
   "source": [
    "train(model=net, criterion=criterion, optimizer=optimizer, train_loader=train_loader_NEU, valid_loader=valid_loader_NEU, batch_size=batch_size, train_on_gpu=train_on_gpu, save_path=save_NEU_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(torch.load(save_NEU_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.726\n",
      "Test accuracy: 0.489 %\n"
     ]
    }
   ],
   "source": [
    "test(model=net, criterion=criterion, test_loader=test_loader_NEU, batch_size=batch_size, train_on_gpu=train_on_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above values, we can conclude that the LSTM gives better results in three personality traits than the one by SVM in the previous notebook. LSTM gives higher scores for Openness, Extroversion and Agreeableness, while SVM reached higher scores for Conscientiousness and Neuroticism."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining the 5 built-in models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a pipeline that takes an essay and predicts the personalities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* First, we will build a function that will preprocess a given essay. It will perform tokenization, cleaning, stopwords removal and finally, pad the review.\n",
    "\n",
    "* Second, we will prepare a function that takes a review and outputs a dictionary of personalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get stopwords list\n",
    "stoplist = stopwords.words('dutch') \n",
    "# get list of punctuations\n",
    "punctuations = string.punctuation + \"’¶•@°©®™\"\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    This function preprocess a given raw text by removing the urls, mentions,\n",
    "    punctuations, stop words, numbers, emojis etc.\n",
    "    \n",
    "    @param text string\n",
    "    @return text string\n",
    "    \"\"\"\n",
    "        \n",
    "    # string to lowercase\n",
    "    txt = text.lower()\n",
    "    \n",
    "    # keep only ascii characters\n",
    "    txt = re.sub(r\"[^a-zA-ZÀ-ÿ]\", \" \", txt)\n",
    "    \n",
    "    # punctuation removal and map it to space\n",
    "    translator = str.maketrans(punctuations, \" \"*len(punctuations))\n",
    "    s = txt.translate(translator)\n",
    "    \n",
    "    # remove digits \n",
    "    no_digits = ''.join([i for i in s if not i.isdigit()])\n",
    "    cleaner = \" \".join(no_digits.split())\n",
    "    \n",
    "    # tokenize words and removing stop words \n",
    "    word_tokens = word_tokenize(cleaner)\n",
    "    filtered_sentence = [w for w in word_tokens if not w in stoplist]\n",
    "    filtered_sentence = \" \".join(filtered_sentence)\n",
    "    \n",
    "    # a stemming word block\n",
    "    filtered_sentence = [stemmer.stem(word) for word in word_tokenize(filtered_sentence)]\n",
    "    filtered_sentence = \" \".join(filtered_sentence)\n",
    "    \n",
    "    # encoding review using our list of words that we generated earler\n",
    "    encoded_review = [word_to_index[word] for word in filtered_sentence.split() if word in word_to_index]\n",
    "    \n",
    "    return encoded_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      "  0.0000e+00 0.0000e+00 9.7000e+01 2.6500e+02 1.4166e+04 5.2000e+02\n",
      "  2.1520e+03 2.3800e+02 1.4000e+01 1.5800e+02 7.9990e+03 4.7460e+03\n",
      "  8.9000e+01 4.0000e+01 3.6000e+01 3.9900e+02 6.2300e+02 1.0530e+03\n",
      "  2.3120e+03 1.6400e+02 5.2000e+02 9.5300e+02 1.4200e+02 5.8000e+01\n",
      "  2.4860e+03 2.0000e+00 1.7700e+02 6.2300e+02 1.0530e+03 2.5600e+02\n",
      "  2.1750e+03 8.8900e+02 2.0000e+00 1.4167e+04 1.5190e+03 3.1580e+03\n",
      "  2.0000e+00 3.3100e+02 1.4168e+04 9.4400e+03 7.3570e+03 2.2900e+02\n",
      "  8.8800e+02 5.8200e+03 3.3270e+03 1.1500e+02 1.3080e+03 7.3580e+03\n",
      "  1.6400e+02 2.4700e+02 7.2400e+02 8.8800e+02 1.0530e+03 9.5300e+02\n",
      "  2.1520e+03 2.4360e+03 4.1700e+02 4.1400e+02 9.8200e+02 3.8300e+02\n",
      "  3.2050e+03 8.8800e+02 3.6500e+02 1.4169e+04 3.1580e+03 3.3780e+03\n",
      "  7.0000e+01 2.2900e+02 8.8800e+02 5.1000e+01 1.0050e+03 6.0610e+03\n",
      "  5.7000e+01 5.9500e+02 9.5300e+02 2.4730e+03 7.3570e+03 3.6050e+03\n",
      "  3.7000e+01 1.6200e+02 8.8800e+02 4.3600e+02 4.3800e+02 9.4410e+03\n",
      "  5.2440e+03 3.1400e+02 5.0500e+02 2.9630e+03 1.7700e+02 6.2300e+02\n",
      "  1.0530e+03 3.2050e+03 8.8800e+02 1.2540e+03 1.7760e+03 1.0000e+00\n",
      "  2.1880e+03 3.7430e+03 2.7000e+02 8.8900e+02 2.2900e+02 8.8800e+02\n",
      "  4.4200e+03 3.3600e+02 4.1700e+02 5.2000e+02 2.9000e+01 1.7700e+02\n",
      "  6.2300e+02 1.0530e+03 5.6460e+03 6.0000e+01 2.1600e+02 3.1920e+03\n",
      "  2.9800e+02 1.1700e+02 2.6700e+02 1.0000e+00 1.9600e+02 5.1400e+02\n",
      "  3.7400e+02 9.5400e+02 3.5500e+02 9.5300e+02 2.1520e+03 1.2500e+02\n",
      "  1.2100e+02 3.3800e+02 2.1520e+03 8.0500e+02 9.4420e+03 8.9300e+02\n",
      "  8.6300e+02 2.1520e+03 1.5640e+03 6.8000e+01 4.6800e+02 2.1520e+03\n",
      "  8.9300e+02 6.0000e+01 2.3200e+02 7.3590e+03 7.3600e+03 2.6800e+03\n",
      "  8.0500e+02 1.2910e+03 2.8640e+03 5.2000e+02 1.0530e+03 1.3240e+03\n",
      "  2.7000e+01 1.2800e+02 4.1400e+02 1.2800e+02 2.8640e+03 1.6000e+01\n",
      "  9.5300e+02 2.3500e+02 1.6000e+01 1.5000e+02 1.8000e+01 1.2500e+03\n",
      "  7.8000e+01 8.3900e+02 5.0000e+00 2.4730e+03 3.1580e+03 7.2000e+01\n",
      "  7.9200e+02 3.6000e+01 7.9970e+03 3.3600e+02 5.4900e+02 1.6000e+01\n",
      "  6.1170e+03 2.3870e+03 3.1580e+03 2.3200e+02 7.2000e+01 6.1170e+03\n",
      "  2.4200e+02 6.0000e+01 4.5600e+02 5.4900e+02 3.1580e+03 8.0500e+02\n",
      "  8.8800e+02 3.7700e+02 5.8000e+01 2.0000e+00 1.0530e+03 4.9900e+02\n",
      "  5.8000e+01 9.5300e+02 2.4730e+03 9.2200e+02 8.3000e+01 1.7980e+03\n",
      "  1.0670e+03 1.5930e+03 8.9300e+02 8.3500e+02 5.8000e+01 2.4860e+03\n",
      "  2.5900e+02 2.1520e+03 1.4170e+04 2.9700e+02 7.3000e+01 6.8000e+01\n",
      "  1.4171e+04 1.7510e+03 2.3880e+03 9.1500e+02 2.4000e+01 8.9300e+02\n",
      "  9.5300e+02 6.0000e+01 4.5600e+02 1.1100e+02 8.9300e+02 2.5850e+03\n",
      "  4.8000e+01 8.3000e+01 9.1500e+02 5.4900e+02 1.2300e+02 3.7000e+01\n",
      "  5.4800e+02 4.4780e+03 5.2050e+03 4.0100e+03 7.3000e+01 1.9390e+03\n",
      "  2.3880e+03 9.4430e+03 1.0900e+03 5.4900e+02 3.8260e+03 3.2400e+02\n",
      "  1.1100e+02 2.1380e+03 9.5300e+02 6.1170e+03 2.7000e+01 1.2800e+02\n",
      "  2.0530e+03 7.3610e+03 6.2300e+02 1.0530e+03 5.0000e+00 1.1700e+02\n",
      "  7.3590e+03 7.3600e+03 1.4172e+04 9.4430e+03 5.0000e+00 1.7240e+03\n",
      "  6.1170e+03 9.5300e+02 7.9000e+01 4.5210e+03 6.8300e+02 5.8590e+03\n",
      "  7.3620e+03 7.3630e+03 9.8000e+01 1.0900e+03 5.1610e+03 6.8300e+02\n",
      "  1.8170e+03 2.5100e+02 1.0530e+03 5.9000e+01 7.3590e+03 7.3600e+03\n",
      "  3.0200e+02 8.8000e+01 1.0000e+00 6.8300e+02 3.8400e+02 5.2000e+02\n",
      "  2.6500e+02 2.9400e+02 2.5680e+03 2.4200e+02 6.0000e+01 4.3800e+02\n",
      "  1.0490e+03 5.2000e+02 1.1800e+02 8.0500e+02 1.2910e+03 5.9130e+03\n",
      "  9.5300e+02 1.9030e+03 1.2800e+02 9.4440e+03 1.9900e+02 3.1960e+03\n",
      "  9.5300e+02 1.9030e+03 1.8820e+03 3.8900e+02 6.8300e+02 6.2300e+02\n",
      "  1.0530e+03 1.8170e+03 2.5100e+02 2.1200e+02 9.5300e+02 1.9030e+03\n",
      "  3.0200e+02 8.9000e+01 2.8310e+03 5.3000e+01]]\n"
     ]
    }
   ],
   "source": [
    "test_essay = \"\"\"\n",
    "Geen geld terug bij teerlongen\n",
    "Een patiënt met longkanker krijgt vaak hoge ziekenhuisrekeningen voorgeschoteld. Gelukkig kan hij, in een land als België, rekenen op een medische terugbetaling. Maar achteraf blijkt dat de patiënt een roker is. Sommigen vinden het oneerlijk dat deze mensen ook recht hebben op medische terugbetaling. Dezelfde opinie heerst bij mensen over alchoholici die lijden aan levercirrose. Hebben deze mensen gelijk of prediken zij onzin? \n",
    "Uit een enquëte bij Belgische artsen van de Vlekho Business School in samenwerking met de Artsenkrant, blijkt dat drie op tien artsen de terugbetaling van rokers met longkanker overbodig vindt. Hierbij denkt ook ongeveer een kwart van de artsen hetzelfde over alcholici met levercirrose. Een significant aantal Belgische artsen staat blijkbaar onverschillig ten opzichte van rokers en alcoholici. De enquëte legde ook een ander voorbeeld voor. De artsen moesten bepalen of een bromfietser die zonder helm valt en daardoor blind wordt, recht heeft op medische terugbetaling. Een kwart van de artsen vond van niet. \n",
    "Uit deze statistieken kunnen we afleiden dat er geen overkoepelende mening heerst bij Belgische artsen. Alhoewel de meerderheid vindt dat deze patiënten nog steeds recht hebben op medische terugbetaling, is de tegenstand zeker niet klein. Om een duidelijker beeld te geven van de situatie, kunnen we best de argumenten van beide standpunten vergelijken. \n",
    "Bij rokers met longkanker denken de meesten meteen dat de longkanker veroorzaakt werd door de tabak. Roken kan zonder twijfel longkanker veroorzaken, maar in alle gevallen van longkanker is roken zeker niet de oorzaak. Zo kan bij een rokende longkankerpatiënt zijn kanker niet veroorzaakt zijn door zijn verslaving. Oordelen of deze patiënt terugbetaling verdient of niet wordt dan heel moeilijk. Hierbij is het ook moeilijk oordelen wanneer je een roker bent en wanneer niet. Dit zijn feiten die eerst grondig bepaald en onderzocht moeten worden. Bij alcoholici met levercirrose wordt het zelfs nog moeilijker. In België consumeert een meerderheid alcohol, maar wanneer ben je een alcoholicus? Daarbovenop kan levercirrose ook andere oorzaken hebben en kan je, zelfs bij een alcoholicus, nooit met 100% zekerheid verklaren dat alcohol de levercirrose heeft veroorzaakt. \n",
    "De artsen die daarentegen vinden dat deze mensen geen terugbetaling verdienen, vinden dat rokers en alcoholici deze aandoeningen aan hun eigen te danken hebben. Ze zijn tenslotte zelf begonnen met roken en drinken. Ze vinden het oneerlijk tegenover de andere longkanker- of levercirrosepatiënten. Tegenwoordig staan op alle pakjes sigaretten waarschuwingen over de risico's van roken. Rokers kunnen zeker niet verklaren dat ze de gevolgen van roken niet kenden. Ze gebruiken het ook op eigen risico. Bij alcohol is het weer een ander verhaal. Op de verpakking van alcoholische dranken staan nergens waarschuwingen over leveraandoeningen. Iemand kan daarmee alcohol consumeren zonder bewust te zijn van de gevolgen. \n",
    "Iemand definiëren als een roker of alcoholicus is heel moeilijk. Vooraleer ziekenfondsen geen medische terugbetalingen meer moeten geven aan rokende longkankerpatiënten of aloholici met een leveraandoening, moeten de begrippen 'alcoholicus' en 'roker' duidelijk gedefinieerd worden. Dit is onmogelijk en zou voor een nachtmerrie van berekeningen en papierwerk zorgen. Het is daarmee juridisch onmogelijk om een stop te zetten op de terugbetaling van bijvoorbeeld rokende longkankerpatiënten. \n",
    "Uiteindelijk zien we dat het onmogelijk is om deze specifieke patiënten niet meer terug te betalen. Een arts kan nooit met 100% zekerheid bepalen of de ziekte van de patiënt echt veroorzaakt is door zijn verslaving. Ook iemand bestempelen als roker of alcoholist is moeilijk, omdat er geen parameters bestaan waarbinnen iemand een roker of alcoholist is. Realistisch gezien is het onmogelijk om deze medische terugbetalingen stop te zetten, waardoor rokers en alcoholisten uiteindelijk als de gelukkigen uit de bus komen. \n",
    "\"\"\"\n",
    "preprocessed_text = preprocess_text(test_essay)\n",
    "print(pad_features([preprocessed_text], 400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_sub_classes(pred):\n",
    "    \"\"\"\n",
    "    This function will return the personality sub class from a given prediction\n",
    "    \"\"\"\n",
    "    if pred > 0 and pred <= 0.2:\n",
    "        return \"very low\"\n",
    "    elif pred > 0.2 and pred <= 0.4:\n",
    "        return \"low\"\n",
    "    elif pred > 0.4 and pred <= 0.6:\n",
    "        return \"medium\"\n",
    "    elif pred > 0.6 and pred <= 0.8:\n",
    "        return \"high\"\n",
    "    else:\n",
    "        return \"very high\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_personality_prediction(model_path, feature_tensor):\n",
    "    # Initializing the five saved models from the main LSTM model class `PersonalityLSTM`\n",
    "    model = PersonalityLSTM(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
    "    \n",
    "    # Loading Openness trained model from .pt file\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    \n",
    "    batch_size = feature_tensor.size(0)\n",
    "    \n",
    "    # initialize the hidden state\n",
    "    h = model.init_hidden(batch_size)\n",
    "    \n",
    "    # get the output from the model\n",
    "    output, h = model(feature_tensor, h)\n",
    "    pred_value = output[0].item()\n",
    "    \n",
    "    return (round(pred_value, 4), get_predictions_sub_classes(pred_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_five_personality_traits(essay):\n",
    "    \"\"\"\n",
    "    It will return the predicted personalities from the given essay as predicted by our model\n",
    "    \"\"\"\n",
    "    \n",
    "    # process and tokenize the review using our `preprocess` function\n",
    "    essay = preprocess_text(essay)\n",
    "    \n",
    "    # padding\n",
    "    features = pad_features([essay], 400)\n",
    "\n",
    "    # convert this numpy array to tensor\n",
    "    feature_tensor = torch.from_numpy(features)\n",
    "\n",
    "    batch_size = feature_tensor.size(0)\n",
    "    \n",
    "    # Initializing the five saved models from the main LSTM model class `PersonalityLSTM`\n",
    "    model_OPN = model_CON = model_EXT = model_AGR = model_NEU = PersonalityLSTM(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
    "    \n",
    "    # get the predictions\n",
    "    OPN_value = get_personality_prediction(save_OPN_path, feature_tensor)\n",
    "    CON_value = get_personality_prediction(save_CON_path, feature_tensor)\n",
    "    EXT_value = get_personality_prediction(save_EXT_path, feature_tensor)\n",
    "    AGR_value = get_personality_prediction(save_AGR_path, feature_tensor)\n",
    "    NEU_value = get_personality_prediction(save_NEU_path, feature_tensor)\n",
    "    \n",
    "    # build the final dictionary with prediction\n",
    "    final_prediction = {\n",
    "        \"Openness\": OPN_value,\n",
    "        \"Conscientiousness\": CON_value,\n",
    "        \"Extroversion\": EXT_value,\n",
    "        \"Agreeableness\": AGR_value,\n",
    "        \"Neuroticism\": NEU_value\n",
    "    }\n",
    "    \n",
    "    return final_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Openness': (0.5231, 'medium'),\n",
       " 'Conscientiousness': (0.5378, 'medium'),\n",
       " 'Extroversion': (0.5487, 'medium'),\n",
       " 'Agreeableness': (0.2483, 'low'),\n",
       " 'Neuroticism': (0.5338, 'medium')}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_five_personality_traits(test_essay)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
